<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIfES 2: aimath_cnn_f32_default.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="AIfES_logo_small.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIfES 2
   &#160;<span id="projectnumber">2.0.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('aimath__cnn__f32__default_8h.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">aimath_cnn_f32_default.h File Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Math functions for <a class="el" href="aimath__f32_8h.html">F32 </a> data type, CNN-specific implementation.  
<a href="#details">More...</a></p>

<p><a href="aimath__cnn__f32__default_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a80dd6f6ad7235bcd71dffe4ad2b70493"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a80dd6f6ad7235bcd71dffe4ad2b70493">aimath_f32_default_conv2d_add</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *input, const uint16_t stride[2], const uint16_t dilation[2], const int16_t padding[2][2], const <a class="el" href="structaitensor.html">aitensor_t</a> *kernel, const void *bias, const uint8_t rotated_kernel, const int16_t *input_use_dims, const int16_t *output_use_dims, const int16_t *kernel_use_dims, <a class="el" href="structaitensor.html">aitensor_t</a> *output)</td></tr>
<tr class="memdesc:a80dd6f6ad7235bcd71dffe4ad2b70493"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs 2D convolution on slices of 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds an optional bias.  <a href="aimath__cnn__f32__default_8h.html#a80dd6f6ad7235bcd71dffe4ad2b70493">More...</a><br /></td></tr>
<tr class="separator:a80dd6f6ad7235bcd71dffe4ad2b70493"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a2407949bafedbdb4671f5fd7e94c90"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a4a2407949bafedbdb4671f5fd7e94c90">aimath_f32_default_conv_transpose2d_add</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *input, const uint16_t stride[2], const uint16_t dilation[2], const int16_t padding[2][2], const <a class="el" href="structaitensor.html">aitensor_t</a> *kernel, const void *bias, const uint8_t rotated_kernel, const int16_t *input_use_dims, const int16_t *output_use_dims, const int16_t *kernel_use_dims, <a class="el" href="structaitensor.html">aitensor_t</a> *output)</td></tr>
<tr class="memdesc:a4a2407949bafedbdb4671f5fd7e94c90"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs 2D transposed convolution (or deconvolution) on slices of 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds an optional bias.  <a href="aimath__cnn__f32__default_8h.html#a4a2407949bafedbdb4671f5fd7e94c90">More...</a><br /></td></tr>
<tr class="separator:a4a2407949bafedbdb4671f5fd7e94c90"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9d848ae4f2579b06f0068ccbc056218"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#ae9d848ae4f2579b06f0068ccbc056218">aimath_f32_default_conv2d_fwd</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *input, const uint16_t stride[2], const uint16_t dilation[2], const uint16_t padding[2], const <a class="el" href="structaitensor.html">aitensor_t</a> *weights, const <a class="el" href="structaitensor.html">aitensor_t</a> *bias, int8_t channel_axis, void *work_space, <a class="el" href="structaitensor.html">aitensor_t</a> *output)</td></tr>
<tr class="memdesc:ae9d848ae4f2579b06f0068ccbc056218"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs 2D convolutions with the given 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds a bias (forward pass of the Conv2D layer)  <a href="aimath__cnn__f32__default_8h.html#ae9d848ae4f2579b06f0068ccbc056218">More...</a><br /></td></tr>
<tr class="separator:ae9d848ae4f2579b06f0068ccbc056218"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82d65dcfee8478b18c4632da09ca64d7"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a82d65dcfee8478b18c4632da09ca64d7">aimath_f32_default_conv2d_bwd</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *x_in, const uint16_t stride[2], const uint16_t dilation[2], const uint16_t padding[2], const <a class="el" href="structaitensor.html">aitensor_t</a> *delta_out, int8_t channel_axis, void *work_space, <a class="el" href="structaitensor.html">aitensor_t</a> *d_weights)</td></tr>
<tr class="memdesc:a82d65dcfee8478b18c4632da09ca64d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the gradients of the Conv2D layer with respect to the weights in <a class="el" href="aimath__f32_8h.html">F32 </a> data type.  <a href="aimath__cnn__f32__default_8h.html#a82d65dcfee8478b18c4632da09ca64d7">More...</a><br /></td></tr>
<tr class="separator:a82d65dcfee8478b18c4632da09ca64d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59c500b4d486ec40b922de8c11c92085"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a59c500b4d486ec40b922de8c11c92085">aimath_f32_default_conv2d_bwd_full</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *delta_out, const uint16_t stride[2], const uint16_t dilation[2], const uint16_t padding[2], const <a class="el" href="structaitensor.html">aitensor_t</a> *weights, int8_t channel_axis, void *work_space, <a class="el" href="structaitensor.html">aitensor_t</a> *delta_in)</td></tr>
<tr class="memdesc:a59c500b4d486ec40b922de8c11c92085"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the gradients of the Conv2D layer with respect to the weights in <a class="el" href="aimath__f32_8h.html">F32 </a> data type.  <a href="aimath__cnn__f32__default_8h.html#a59c500b4d486ec40b922de8c11c92085">More...</a><br /></td></tr>
<tr class="separator:a59c500b4d486ec40b922de8c11c92085"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a95836b8bf809d28bb88d54ae66555798"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a95836b8bf809d28bb88d54ae66555798">aimath_f32_default_conv_transpose2d_fwd</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *input, const uint16_t stride[2], const uint16_t dilation[2], const uint16_t padding[2], const uint16_t output_padding[2], const <a class="el" href="structaitensor.html">aitensor_t</a> *weights, const <a class="el" href="structaitensor.html">aitensor_t</a> *bias, int8_t channel_axis, void *work_space, <a class="el" href="structaitensor.html">aitensor_t</a> *output)</td></tr>
<tr class="memdesc:a95836b8bf809d28bb88d54ae66555798"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs 2D transposed convolutions with the given 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds a bias (forward pass of the ConvTranspose2D layer)  <a href="aimath__cnn__f32__default_8h.html#a95836b8bf809d28bb88d54ae66555798">More...</a><br /></td></tr>
<tr class="separator:a95836b8bf809d28bb88d54ae66555798"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a084f32feda31c8ae1e82e769d900910b"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a084f32feda31c8ae1e82e769d900910b">aimath_f32_default_maxpool2d_fwd</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *input, const uint16_t pool_size[2], const uint16_t stride[2], const uint16_t padding[2], int8_t channel_axis, void *work_space, uint32_t *max_locations, <a class="el" href="structaitensor.html">aitensor_t</a> *output)</td></tr>
<tr class="memdesc:a084f32feda31c8ae1e82e769d900910b"><td class="mdescLeft">&#160;</td><td class="mdescRight">2D max-pooling on 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors  <a href="aimath__cnn__f32__default_8h.html#a084f32feda31c8ae1e82e769d900910b">More...</a><br /></td></tr>
<tr class="separator:a084f32feda31c8ae1e82e769d900910b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6752d0d55e6997f87e3a90b1d25e8159"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a6752d0d55e6997f87e3a90b1d25e8159">aimath_f32_default_maxpool2d_bwd</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *delta_out, const uint16_t pool_size[2], const uint16_t stride[2], const uint16_t padding[2], int8_t channel_axis, void *work_space, const uint32_t *max_locations, <a class="el" href="structaitensor.html">aitensor_t</a> *delta_in)</td></tr>
<tr class="memdesc:a6752d0d55e6997f87e3a90b1d25e8159"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the gradients of the MaxPool2D layer with respect to the input in <a class="el" href="aimath__f32_8h.html">F32 </a> data type.  <a href="aimath__cnn__f32__default_8h.html#a6752d0d55e6997f87e3a90b1d25e8159">More...</a><br /></td></tr>
<tr class="separator:a6752d0d55e6997f87e3a90b1d25e8159"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74e774cfbfaf200251822ebb18a162f1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a74e774cfbfaf200251822ebb18a162f1">aimath_f32_default_batch_norm</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *x, int8_t axis, const <a class="el" href="structaitensor.html">aitensor_t</a> *means, const <a class="el" href="structaitensor.html">aitensor_t</a> *variances, const <a class="el" href="structaitensor.html">aitensor_t</a> *offsets, const <a class="el" href="structaitensor.html">aitensor_t</a> *scales, const void *eps, <a class="el" href="structaitensor.html">aitensor_t</a> *result)</td></tr>
<tr class="memdesc:a74e774cfbfaf200251822ebb18a162f1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Batch Normalization on <a class="el" href="aimath__f32_8h.html">F32 </a> tensors.  <a href="aimath__cnn__f32__default_8h.html#a74e774cfbfaf200251822ebb18a162f1">More...</a><br /></td></tr>
<tr class="separator:a74e774cfbfaf200251822ebb18a162f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4332d4dfefbac8588b33e17bf2d95f08"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a4332d4dfefbac8588b33e17bf2d95f08">aimath_f32_default_d_batch_norm</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *x_in, int8_t axis, const <a class="el" href="structaitensor.html">aitensor_t</a> *means, const <a class="el" href="structaitensor.html">aitensor_t</a> *vars, const <a class="el" href="structaitensor.html">aitensor_t</a> *betas, const <a class="el" href="structaitensor.html">aitensor_t</a> *gammas, const <a class="el" href="structaitensor.html">aitensor_t</a> *delta_out, const void *eps, <a class="el" href="structaitensor.html">aitensor_t</a> *delta_in, <a class="el" href="structaitensor.html">aitensor_t</a> *d_betas, <a class="el" href="structaitensor.html">aitensor_t</a> *d_gammas)</td></tr>
<tr class="memdesc:a4332d4dfefbac8588b33e17bf2d95f08"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculates the gradients of Batch Normalization with respect to betas, gammas and the input in <a class="el" href="aimath__f32_8h.html">F32 </a> data type.  <a href="aimath__cnn__f32__default_8h.html#a4332d4dfefbac8588b33e17bf2d95f08">More...</a><br /></td></tr>
<tr class="separator:a4332d4dfefbac8588b33e17bf2d95f08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2374fcf6d4594baa2d9e5aa91da07b34"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="aimath__cnn__f32__default_8h.html#a2374fcf6d4594baa2d9e5aa91da07b34">aimath_f32_default_pad_zeros</a> (const <a class="el" href="structaitensor.html">aitensor_t</a> *x, const uint16_t(*padding)[2], <a class="el" href="structaitensor.html">aitensor_t</a> *result)</td></tr>
<tr class="memdesc:a2374fcf6d4594baa2d9e5aa91da07b34"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pads a <a class="el" href="aimath__f32_8h.html">F32 </a> tensor with zeros.  <a href="aimath__cnn__f32__default_8h.html#a2374fcf6d4594baa2d9e5aa91da07b34">More...</a><br /></td></tr>
<tr class="separator:a2374fcf6d4594baa2d9e5aa91da07b34"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Math functions for <a class="el" href="aimath__f32_8h.html">F32 </a> data type, CNN-specific implementation. </p>
<dl class="section version"><dt>Version</dt><dd>2.0alpha </dd></dl>
<dl class="section copyright"><dt>Copyright</dt><dd>Copyright (C) 2020-2021 Fraunhofer Institute for Microelectronic Circuits and Systems. All rights reserved.<br  />
<br  />
 AIfES is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.<br  />
<br  />
 This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.<br  />
<br  />
 You should have received a copy of the GNU Affero General Public License along with this program. If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</dd></dl>
<p>These functions can be used when no hardware specific implementation is available. </p>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="a74e774cfbfaf200251822ebb18a162f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a74e774cfbfaf200251822ebb18a162f1">&#9670;&nbsp;</a></span>aimath_f32_default_batch_norm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_batch_norm </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>variances</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>offsets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>scales</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>eps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Batch Normalization on <a class="el" href="aimath__f32_8h.html">F32 </a> tensors. </p>
<p>Performs the Batch Normalization operation (proposed by Ioffe and Szegedy, <a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>):<br  />
 </p><p class="formulaDsp">
\[ y_{i,j} = \mathit{BN}(x_{i,j}) = \gamma_i \cdot \frac{x_{i,j} - \mu_{i}}{\sqrt{\sigma_{i}^2+\epsilon}} + \beta_i \]
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>Input tensor (N-D) </td></tr>
    <tr><td class="paramname">axis</td><td>Axis of the input tensor that stores the channel dimension. </td></tr>
    <tr><td class="paramname">means</td><td>1D vector with the means ( \( \mu_i \)) of every channel. </td></tr>
    <tr><td class="paramname">variances</td><td>1D vector with the variances ( \( \sigma^2_i \)) of every channel. </td></tr>
    <tr><td class="paramname">offsets</td><td>1D vector with the offset parameters ( \( \beta_i \)) of every channel. </td></tr>
    <tr><td class="paramname">scales</td><td>1D vector with the scaling parameters ( \( \gamma_i \)) of every channel. </td></tr>
    <tr><td class="paramname">eps</td><td>Small constant for numerical stability. </td></tr>
    <tr><td class="paramname">result</td><td>The resulting normalized tensor (N-D) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a80dd6f6ad7235bcd71dffe4ad2b70493"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80dd6f6ad7235bcd71dffe4ad2b70493">&#9670;&nbsp;</a></span>aimath_f32_default_conv2d_add()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_conv2d_add </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2][2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>kernel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t&#160;</td>
          <td class="paramname"><em>rotated_kernel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>input_use_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>output_use_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>kernel_use_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs 2D convolution on slices of 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds an optional bias. </p>
<p>The function takes 2D slices out of 4D tensors and performs a 2D convolution. The result is then added to the output slice. This technique allows the use of one function for all use-cases (different order like HWC or CHW; different cases in forward and backward pass).</p>
<p>To configure the slices for the convolution, an index array has to be passed for input, kernel and output tensor. The dimension of H is indicated with -1 and W with -2.<br  />
Example: [1, 5, -1, -2] -&gt; Perform a 2D convolution on the last two dimensions. The other two dimensions have indices 1 and 5.</p>
<p>The output dimensions of the height and width are given as: </p><p class="formulaDsp">
\[ H_{out} = floor \left( \frac{H_{in} + P_{h,top} + P_{h,bottom} - D_h \times (H_{kernel} - 1) - 1}{S_h} \right) + 1 \]
</p>
 <p class="formulaDsp">
\[ W_{out} = floor \left( \frac{W_{in} + P_{w,left} + P_{w,right} - D_w \times (W_{kernel} - 1) - 1}{S_w} \right) + 1 \]
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input tensor (4D) </td></tr>
    <tr><td class="paramname">stride</td><td>Stride in the direction of height and width </td></tr>
    <tr><td class="paramname">dilation</td><td>Dilation of the kernel tensor in the direction of height and width </td></tr>
    <tr><td class="paramname">padding</td><td>Asymmetric zero padding in the direction of height and width \( [[P_{h,top},P_{h,bottom}],[P_{w,left},P_{w,right}]] \) </td></tr>
    <tr><td class="paramname">kernel</td><td>Kernel / Weights tensor (4D) </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias tensor (1D; set to null if not in use) </td></tr>
    <tr><td class="paramname">rotated_kernel</td><td>Determines whether or not to rotate the kernel by 180°; default is TRUE (1) </td></tr>
    <tr><td class="paramname">input_use_dims</td><td>Indices for the 2D slice of the input tensor (-1 for the height dimension and -2 for the width dimension) </td></tr>
    <tr><td class="paramname">output_use_dims</td><td>Indices for the 2D slice of the output tensor (-1 for the height dimension and -2 for the width dimension) </td></tr>
    <tr><td class="paramname">kernel_use_dims</td><td>Indices for the 2D slice of the kernel tensor (-1 for the height dimension and -2 for the width dimension) </td></tr>
    <tr><td class="paramname">output</td><td>Output tensor to add the result to (4D) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a82d65dcfee8478b18c4632da09ca64d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82d65dcfee8478b18c4632da09ca64d7">&#9670;&nbsp;</a></span>aimath_f32_default_conv2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_conv2d_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>x_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>channel_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>work_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>d_weights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the gradients of the Conv2D layer with respect to the weights in <a class="el" href="aimath__f32_8h.html">F32 </a> data type. </p>
<p>Calculates the gradients with respect to the weights \( \partial w = \mathrm{d} L / \mathrm{d} w \).</p>
<p class="formulaDsp">
\[ \partial w = x_{in} \ast delta_{out} \]
</p>
<p>This function wraps the <a class="el" href="aimath__cnn__f32__default_8h.html#a80dd6f6ad7235bcd71dffe4ad2b70493" title="Performs 2D convolution on slices of 4D F32  tensors and adds an optional bias.">aimath_f32_default_conv2d_add()</a> function to perform the backward pass of a Conv2D layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x_in</td><td>Input data with dimension \( [N,C_{in},H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">stride</td><td>The stride in the direction of height and width </td></tr>
    <tr><td class="paramname">dilation</td><td>The dilation in the direction of height and width </td></tr>
    <tr><td class="paramname">padding</td><td>The (symmetric) zero padding in the direction of height and width </td></tr>
    <tr><td class="paramname">delta_out</td><td>Gradients backpropagated from the following layer with dimension \( [N,C_{out},H_{out},W_{out}] \) (channels first) or \( [N,H_{out},W_{out},C_{out}] \) (channels last) </td></tr>
    <tr><td class="paramname">channel_axis</td><td>Index of the channel axis (1 for channels first and -1 or 3 for channels last). </td></tr>
    <tr><td class="paramname">work_space</td><td>Pointer to a work space buffer for intermediate results (Not in use) </td></tr>
    <tr><td class="paramname">d_weights</td><td>Output gradients of the weights with dimension \( [C_{out},C_{in},H_{kernel},W_{kernel}] \) (channels first) or \( [C_{out},H_{kernel},W_{kernel},C_{in}] \) (channels last) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a59c500b4d486ec40b922de8c11c92085"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a59c500b4d486ec40b922de8c11c92085">&#9670;&nbsp;</a></span>aimath_f32_default_conv2d_bwd_full()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_conv2d_bwd_full </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>channel_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>work_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the gradients of the Conv2D layer with respect to the weights in <a class="el" href="aimath__f32_8h.html">F32 </a> data type. </p>
<p>Calculates the gradients with respect to the input \( delta_{in} = \mathrm{d} L / \mathrm{d} x_{in} \).</p>
<p class="formulaDsp">
\[ delta_{in} = delta_{out} \ast&#39; w \]
</p>
<p> \( \cdot \ast&#39; \cdot \) is a transposed convolution.</p>
<p>This function wraps the <a class="el" href="aimath__cnn__f32__default_8h.html#a4a2407949bafedbdb4671f5fd7e94c90" title="Performs 2D transposed convolution (or deconvolution) on slices of 4D F32  tensors and adds an option...">aimath_f32_default_conv_transpose2d_add()</a> function to perform the backward pass of a Conv2D layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">delta_out</td><td>Gradients backpropagated from the following layer with dimension \( [N,C_{in},H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">stride</td><td>The stride in the direction of height and width </td></tr>
    <tr><td class="paramname">dilation</td><td>The dilation in the direction of height and width </td></tr>
    <tr><td class="paramname">padding</td><td>The (symmetric) zero padding in the direction of height and width </td></tr>
    <tr><td class="paramname">weights</td><td>Convolution kernels with dimension \( [C_{out},C_{in},H_{kernel},W_{kernel}] \) (channels first) or \( [C_{out},H_{kernel},W_{kernel},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">channel_axis</td><td>Index of the channel axis (1 for channels first and -1 or 3 for channels last). </td></tr>
    <tr><td class="paramname">work_space</td><td>Pointer to a work space buffer for intermediate results. </td></tr>
    <tr><td class="paramname">delta_in</td><td>Resulting input gradients for backpropagation to the previous layer with dimension \( [N,C_{in},H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C_{in}] \) (channels last) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae9d848ae4f2579b06f0068ccbc056218"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9d848ae4f2579b06f0068ccbc056218">&#9670;&nbsp;</a></span>aimath_f32_default_conv2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_conv2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>channel_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>work_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs 2D convolutions with the given 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds a bias (forward pass of the Conv2D layer) </p>
<p class="formulaDsp">
\[ x_{out} = x_{in} \ast w + b \]
</p>
<p>This function wraps the <a class="el" href="aimath__cnn__f32__default_8h.html#a80dd6f6ad7235bcd71dffe4ad2b70493" title="Performs 2D convolution on slices of 4D F32  tensors and adds an optional bias.">aimath_f32_default_conv2d_add()</a> function to perform the forward pass of a Conv2D layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input ( \( x_{in} \)) data with dimension \( [N,C_{in},H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">stride</td><td>The stride in the direction of height and width </td></tr>
    <tr><td class="paramname">dilation</td><td>The dilation in the direction of height and width </td></tr>
    <tr><td class="paramname">padding</td><td>The (symmetric) zero padding in the direction of height and width </td></tr>
    <tr><td class="paramname">weights</td><td>Convolution kernels with dimension \( [C_{out},C_{in},H_{kernel},W_{kernel}] \) (channels first) or \( [C_{out},H_{kernel},W_{kernel},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">bias</td><td>Bias with dimension \( C_{out} \) </td></tr>
    <tr><td class="paramname">channel_axis</td><td>Index of the channel axis (1 for channels first and -1 or 3 for channels last). </td></tr>
    <tr><td class="paramname">work_space</td><td>Pointer to a work space buffer for intermediate results (Not in use) </td></tr>
    <tr><td class="paramname">output</td><td>Output ( \( x_{out} \)) after convolution with dimension \( [N,C_{out},H_{out},W_{out}] \) (channels first) or \( [N,H_{out},W_{out},C_{out}] \) (channels last) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4a2407949bafedbdb4671f5fd7e94c90"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a2407949bafedbdb4671f5fd7e94c90">&#9670;&nbsp;</a></span>aimath_f32_default_conv_transpose2d_add()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_conv_transpose2d_add </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2][2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>kernel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint8_t&#160;</td>
          <td class="paramname"><em>rotated_kernel</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>input_use_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>output_use_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>kernel_use_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs 2D transposed convolution (or deconvolution) on slices of 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds an optional bias. </p>
<p>The function takes 2D slices out of 4D tensors and performs a 2D transposed convolution. The result is then added to the output slice. This technique allows the use of one function for all use-cases (different order like HWC or CHW; different cases in forward and backward pass).</p>
<p>To configure the slices for the transposed convolution, an index array has to be passed for input, kernel and output tensor. The dimension of H is indicated with -1 and W with -2.<br  />
Example: [1, 5, -1, -2] -&gt; Perform a 2D transposed convolution on the last two dimensions. The other two dimensions have indices 1 and 5.</p>
<p>The output dimensions of the height and width are given as: </p><p class="formulaDsp">
\[ H_{out} = S_h \times (H_{in}-1)+1 + P_{h,top} + P_{h,bottom} - D_h \times (H_{kernel} - 1) \]
</p>
 <p class="formulaDsp">
\[ W_{out} = S_w \times (W_{in}-1)+1 + P_{w,left} + P_{w,right} - D_w \times (W_{kernel} - 1) \]
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input tensor (4D) </td></tr>
    <tr><td class="paramname">stride</td><td>Dilation of the input tensor in the direction of height and width </td></tr>
    <tr><td class="paramname">dilation</td><td>Dilation of the kernel tensor in the direction of height and width </td></tr>
    <tr><td class="paramname">padding</td><td>Asymmetric zero padding in the direction of height and width \( [[P_{h,top},P_{h,bottom}],[P_{w,left},P_{w,right}]] \) </td></tr>
    <tr><td class="paramname">kernel</td><td>Kernel / Weights tensor (4D) </td></tr>
    <tr><td class="paramname">bias</td><td>Optional bias tensor (1D; set to null if not in use) </td></tr>
    <tr><td class="paramname">rotated_kernel</td><td>Determines whether or not to rotate the kernel by 180°; default is TRUE (1) </td></tr>
    <tr><td class="paramname">input_use_dims</td><td>Indices for the 2D slice of the input tensor (-1 for the height dimension and -2 for the width dimension) </td></tr>
    <tr><td class="paramname">output_use_dims</td><td>Indices for the 2D slice of the output tensor (-1 for the height dimension and -2 for the width dimension) </td></tr>
    <tr><td class="paramname">kernel_use_dims</td><td>Indices for the 2D slice of the kernel tensor (-1 for the height dimension and -2 for the width dimension) </td></tr>
    <tr><td class="paramname">output</td><td>Output tensor to add the result to (4D) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a95836b8bf809d28bb88d54ae66555798"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a95836b8bf809d28bb88d54ae66555798">&#9670;&nbsp;</a></span>aimath_f32_default_conv_transpose2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_conv_transpose2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dilation</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>output_padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>channel_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>work_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs 2D transposed convolutions with the given 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors and adds a bias (forward pass of the ConvTranspose2D layer) </p>
<p class="formulaDsp">
\[ x_{out} = x_{in} \ast&#39; w + b \]
</p>
<p> \( \cdot \ast&#39; \cdot \) is a transposed convolution.</p>
<p>This function wraps the <a class="el" href="aimath__cnn__f32__default_8h.html#a4a2407949bafedbdb4671f5fd7e94c90" title="Performs 2D transposed convolution (or deconvolution) on slices of 4D F32  tensors and adds an option...">aimath_f32_default_conv_transpose2d_add()</a> function to perform the forward pass of a ConvTranspose2D layer.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input ( \( x_{in} \)) data with dimension \( [N,C_{in},H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">stride</td><td>Dilation of the input in the direction of height and width </td></tr>
    <tr><td class="paramname">dilation</td><td>Dilation of the kernel in the direction of height and width </td></tr>
    <tr><td class="paramname">padding</td><td>The (symmetric) zero padding in the direction of height and width </td></tr>
    <tr><td class="paramname">output_padding</td><td>Additional asymmetric zero padding on one side in the direction of height and width </td></tr>
    <tr><td class="paramname">weights</td><td>Convolution kernels with dimension \( [C_{out},C_{in},H_{kernel},W_{kernel}] \) (channels first) or \( [C_{out},H_{kernel},W_{kernel},C_{in}] \) (channels last) </td></tr>
    <tr><td class="paramname">bias</td><td>Bias with dimension \( C_{out} \) </td></tr>
    <tr><td class="paramname">channel_axis</td><td>Index of the channel axis (1 for channels first and -1 or 3 for channels last). </td></tr>
    <tr><td class="paramname">work_space</td><td>Pointer to a work space buffer for intermediate results (Not in use) </td></tr>
    <tr><td class="paramname">output</td><td>Output ( \( x_{out} \)) after convolution with dimension \( [N,C_{out},H_{out},W_{out}] \) (channels first) or \( [N,H_{out},W_{out},C_{out}] \) (channels last) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4332d4dfefbac8588b33e17bf2d95f08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4332d4dfefbac8588b33e17bf2d95f08">&#9670;&nbsp;</a></span>aimath_f32_default_d_batch_norm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_d_batch_norm </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>x_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>means</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>vars</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>betas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>gammas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>eps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>d_betas</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>d_gammas</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the gradients of Batch Normalization with respect to betas, gammas and the input in <a class="el" href="aimath__f32_8h.html">F32 </a> data type. </p>
<p>Calculates the derivative of the Batch Normalization with respect to the input and the trainable parameters ( \( \beta \) and \( \gamma \)).<br  />
 Please refer to the paper by Ioffe and Szegedy (<a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>) for the equations of the gradients.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x_in</td><td>Input tensor (N-D) </td></tr>
    <tr><td class="paramname">axis</td><td>Axis of the input tensor that stores the channel dimension. </td></tr>
    <tr><td class="paramname">means</td><td>1D vector with the means ( \( \mu_i \)) of every channel. </td></tr>
    <tr><td class="paramname">vars</td><td>1D vector with the variances ( \( \sigma^2_i \)) of every channel. </td></tr>
    <tr><td class="paramname">betas</td><td>1D vector with the offset parameters ( \( \beta_i \)) of every channel. </td></tr>
    <tr><td class="paramname">gammas</td><td>1D vector with the scaling parameters ( \( \gamma_i \)) of every channel. </td></tr>
    <tr><td class="paramname">delta_out</td><td>Gradient calculated by the output layer for gradient backpropagation (N-D) </td></tr>
    <tr><td class="paramname">eps</td><td>Small constant for numerical stability. </td></tr>
    <tr><td class="paramname">delta_in</td><td>The resulting gradients of the input ( \( \mathrm{d}\mathcal{L} / \mathrm{d}x \)). </td></tr>
    <tr><td class="paramname">d_betas</td><td>The resulting gradients of the \( \beta \) parameter ( \( \mathrm{d}\mathcal{L} / \mathrm{d}\beta \)). </td></tr>
    <tr><td class="paramname">d_gammas</td><td>The resulting gradients of the \( \gamma \) parameter ( \( \mathrm{d}\mathcal{L} / \mathrm{d}\gamma \)). </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a6752d0d55e6997f87e3a90b1d25e8159"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6752d0d55e6997f87e3a90b1d25e8159">&#9670;&nbsp;</a></span>aimath_f32_default_maxpool2d_bwd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_maxpool2d_bwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pool_size</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>channel_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>work_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint32_t *&#160;</td>
          <td class="paramname"><em>max_locations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>delta_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculates the gradients of the MaxPool2D layer with respect to the input in <a class="el" href="aimath__f32_8h.html">F32 </a> data type. </p>
<p>Calculates the gradients with respect to the input \( delta_{in} = \mathrm{d} L / \mathrm{d} x_{in} \).</p>
<p>This is done by simply copying the output gradient to the position in the input gradients depicted by max_locations.<br  />
An element of max_locations consist of the concatenated 16-bit indices for height and width in the pooling window.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">delta_out</td><td>Gradients backpropagated from the following layer with dimension \( [N,C,H_{out},W_{out}] \) (channels first) or \( [N,H_{out},W_{out},C] \) (channels last) </td></tr>
    <tr><td class="paramname">pool_size</td><td>The size of the pooling window (height and width) </td></tr>
    <tr><td class="paramname">stride</td><td>The stride in the direction of height and width. </td></tr>
    <tr><td class="paramname">padding</td><td>The (symmetric) minus infinity padding in the direction of height and width </td></tr>
    <tr><td class="paramname">channel_axis</td><td>Index of the channel axis (1 for channels first and -1 or 3 for channels last). </td></tr>
    <tr><td class="paramname">work_space</td><td>Pointer to a work space buffer for intermediate results. </td></tr>
    <tr><td class="paramname">max_locations</td><td>Pointer to memory section where the indices of the maximum values per pooling window are stored. </td></tr>
    <tr><td class="paramname">delta_in</td><td>Resulting input gradients for backpropagation to the previous layer \( [N,C,H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C] \) (channels last) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a084f32feda31c8ae1e82e769d900910b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a084f32feda31c8ae1e82e769d900910b">&#9670;&nbsp;</a></span>aimath_f32_default_maxpool2d_fwd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_maxpool2d_fwd </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>pool_size</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>stride</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t&#160;</td>
          <td class="paramname"><em>channel_axis</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>work_space</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t *&#160;</td>
          <td class="paramname"><em>max_locations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>2D max-pooling on 4D <a class="el" href="aimath__f32_8h.html">F32 </a> tensors </p>
<p>Performs a 2D max-pooling operation on 2D slices of a 4D input tensor. This function is used as the forward pass of the MaxPool2D layer.</p>
<p>For training (max_locations != 0), the index of the max-value in the kernel window is be stored in max_locations.<br  />
An element of max_locations simply consist of the concatenated 16-bit indices for height and width in the pooling window.</p>
<p>The output dimensions of the height and width are given as: </p><p class="formulaDsp">
\[ H_{out} = floor \left( \frac{H_{in} + 2 * P_h - H_{pool}}{S_h} \right) + 1 \]
</p>
 <p class="formulaDsp">
\[ W_{out} = floor \left( \frac{W_{in} + 2 * P_w - W_{pool}}{S_w} \right) + 1 \]
</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input data with dimension \( [N,C,H_{in},W_{in}] \) (channels first) or \( [N,H_{in},W_{in},C] \) (channels last) </td></tr>
    <tr><td class="paramname">pool_size</td><td>The size of the pooling window (height and width) </td></tr>
    <tr><td class="paramname">stride</td><td>The stride in the direction of height and width. </td></tr>
    <tr><td class="paramname">padding</td><td>The (symmetric) minus infinity padding in the direction of height and width </td></tr>
    <tr><td class="paramname">channel_axis</td><td>Index of the channel axis (1 for channels first and -1 or 3 for channels last). </td></tr>
    <tr><td class="paramname">work_space</td><td>Pointer to a work space buffer for intermediate results. </td></tr>
    <tr><td class="paramname">max_locations</td><td>Pointer to memory section where the indices of the maximum values per pooling window are stored. </td></tr>
    <tr><td class="paramname">output</td><td>Output after max-pooling with dimension \( [N,C,H_{out},W_{out}] \) (channels first) or \( [N,H_{out},W_{out},C] \) (channels last) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a2374fcf6d4594baa2d9e5aa91da07b34"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2374fcf6d4594baa2d9e5aa91da07b34">&#9670;&nbsp;</a></span>aimath_f32_default_pad_zeros()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void aimath_f32_default_pad_zeros </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t(*)&#160;</td>
          <td class="paramname"><em>padding</em>[2], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structaitensor.html">aitensor_t</a> *&#160;</td>
          <td class="paramname"><em>result</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Pads a <a class="el" href="aimath__f32_8h.html">F32 </a> tensor with zeros. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>Input F32 tensor (N-D) </td></tr>
    <tr><td class="paramname">padding</td><td>Array of the asymmetric zero paddings for each dimension of the input tensor </td></tr>
    <tr><td class="paramname">result</td><td>Resulting padded F32 tensor (N-D) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_5233a5861230ad4bc52bfd822c86fe04.html">cnn</a></li><li class="navelem"><a class="el" href="dir_af585f9a5a89e54017897db60f1719d0.html">default</a></li><li class="navelem"><a class="el" href="dir_b079fac787a650d75de05d71be2d2bed.html">aimath</a></li><li class="navelem"><a class="el" href="aimath__cnn__f32__default_8h.html">aimath_cnn_f32_default.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
