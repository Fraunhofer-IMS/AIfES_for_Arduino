<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AIfES 2: ailayer_batch_normalization.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="AIfES_logo_small.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AIfES 2
   &#160;<span id="projectnumber">2.0.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('ailayer__batch__normalization_8h.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#typedef-members">Typedefs</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">ailayer_batch_normalization.h File Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Base <a class="el" href="structailayer.html">layer </a> implementation of the Batch Normalization layer.  
<a href="#details">More...</a></p>

<p><a href="ailayer__batch__normalization_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structailayer__batch__norm.html">ailayer_batch_norm</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">General <a class="el" href="ailayer__batch__normalization_8h.html">Batch Normalization layer </a> structure.  <a href="structailayer__batch__norm.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:aafd99affc6ad5f0a7452751bdbd92f1c"><td class="memItemLeft" align="right" valign="top"><a id="aafd99affc6ad5f0a7452751bdbd92f1c"></a>
typedef struct <a class="el" href="structailayer__batch__norm.html">ailayer_batch_norm</a>&#160;</td><td class="memItemRight" valign="bottom"><b>ailayer_batch_norm_t</b></td></tr>
<tr class="separator:aafd99affc6ad5f0a7452751bdbd92f1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a43542b80dbaf9d65f72251d938dd0d84"><td class="memItemLeft" align="right" valign="top"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#a43542b80dbaf9d65f72251d938dd0d84">ailayer_batch_norm</a> (<a class="el" href="structailayer__batch__norm.html">ailayer_batch_norm_t</a> *layer, <a class="el" href="structailayer.html">ailayer_t</a> *input_layer)</td></tr>
<tr class="memdesc:a43542b80dbaf9d65f72251d938dd0d84"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialize and connect the given Batch Normalization layer.  <a href="ailayer__batch__normalization_8h.html#a43542b80dbaf9d65f72251d938dd0d84">More...</a><br /></td></tr>
<tr class="separator:a43542b80dbaf9d65f72251d938dd0d84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4143200f8e1c9a9ee8a4292c91c6adb4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#a4143200f8e1c9a9ee8a4292c91c6adb4">ailayer_batch_norm_forward</a> (<a class="el" href="structailayer.html">ailayer_t</a> *self)</td></tr>
<tr class="memdesc:a4143200f8e1c9a9ee8a4292c91c6adb4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the forward pass for given Batch Normalization layer.  <a href="ailayer__batch__normalization_8h.html#a4143200f8e1c9a9ee8a4292c91c6adb4">More...</a><br /></td></tr>
<tr class="separator:a4143200f8e1c9a9ee8a4292c91c6adb4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a23613b98279575ed47e067fb92c195fa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#a23613b98279575ed47e067fb92c195fa">ailayer_batch_norm_backward</a> (<a class="el" href="structailayer.html">ailayer_t</a> *self)</td></tr>
<tr class="memdesc:a23613b98279575ed47e067fb92c195fa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the backward pass for the given Batch Normalization layer.  <a href="ailayer__batch__normalization_8h.html#a23613b98279575ed47e067fb92c195fa">More...</a><br /></td></tr>
<tr class="separator:a23613b98279575ed47e067fb92c195fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeae1413817112d97e2c6148780e23624"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#aeae1413817112d97e2c6148780e23624">ailayer_batch_norm_calc_result_shape</a> (<a class="el" href="structailayer.html">ailayer_t</a> *self)</td></tr>
<tr class="memdesc:aeae1413817112d97e2c6148780e23624"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the shape of the result tensor (<a class="el" href="structailayer.html#a1ed86d1fec7aae68bc79c55f3f965790" title="The result of the forward function is stored here.">ailayer.result</a>)  <a href="ailayer__batch__normalization_8h.html#aeae1413817112d97e2c6148780e23624">More...</a><br /></td></tr>
<tr class="separator:aeae1413817112d97e2c6148780e23624"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca69f294f48ca9f4c474d3a75d5bb5b4"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#aca69f294f48ca9f4c474d3a75d5bb5b4">ailayer_batch_norm_sizeof_paramem</a> (const <a class="el" href="structailayer.html">ailayer_t</a> *self)</td></tr>
<tr class="memdesc:aca69f294f48ca9f4c474d3a75d5bb5b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate and return the parameter memory size needed for this layer.  <a href="ailayer__batch__normalization_8h.html#aca69f294f48ca9f4c474d3a75d5bb5b4">More...</a><br /></td></tr>
<tr class="separator:aca69f294f48ca9f4c474d3a75d5bb5b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3476d9d38ffe89b267e68b1c3fc748d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#ae3476d9d38ffe89b267e68b1c3fc748d">ailayer_batch_norm_set_paramem</a> (<a class="el" href="structailayer.html">ailayer_t</a> *self, void *memory_ptr)</td></tr>
<tr class="memdesc:ae3476d9d38ffe89b267e68b1c3fc748d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Distribute provided memory to the parameter pointers.  <a href="ailayer__batch__normalization_8h.html#ae3476d9d38ffe89b267e68b1c3fc748d">More...</a><br /></td></tr>
<tr class="separator:ae3476d9d38ffe89b267e68b1c3fc748d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a39b286297ae7e1163676e98b4c9d21ea"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#a39b286297ae7e1163676e98b4c9d21ea">ailayer_batch_norm_sizeof_trainmem</a> (const <a class="el" href="structailayer.html">ailayer_t</a> *self)</td></tr>
<tr class="memdesc:a39b286297ae7e1163676e98b4c9d21ea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate and return the memory size needed by this layer for training.  <a href="ailayer__batch__normalization_8h.html#a39b286297ae7e1163676e98b4c9d21ea">More...</a><br /></td></tr>
<tr class="separator:a39b286297ae7e1163676e98b4c9d21ea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7047892ab2ce5b21a2581f47d8b43c60"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#a7047892ab2ce5b21a2581f47d8b43c60">ailayer_batch_norm_set_trainmem</a> (<a class="el" href="structailayer.html">ailayer_t</a> *self, void *memory_ptr)</td></tr>
<tr class="memdesc:a7047892ab2ce5b21a2581f47d8b43c60"><td class="mdescLeft">&#160;</td><td class="mdescRight">Distribute provided memory to the gradients pointers.  <a href="ailayer__batch__normalization_8h.html#a7047892ab2ce5b21a2581f47d8b43c60">More...</a><br /></td></tr>
<tr class="separator:a7047892ab2ce5b21a2581f47d8b43c60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa314fea512774e4b63bc25da3b030476"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#aa314fea512774e4b63bc25da3b030476">ailayer_batch_norm_print_specs</a> (const <a class="el" href="structailayer.html">ailayer_t</a> *self)</td></tr>
<tr class="memdesc:aa314fea512774e4b63bc25da3b030476"><td class="mdescLeft">&#160;</td><td class="mdescRight">Print the layer specification.  <a href="ailayer__batch__normalization_8h.html#aa314fea512774e4b63bc25da3b030476">More...</a><br /></td></tr>
<tr class="separator:aa314fea512774e4b63bc25da3b030476"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:af4710b2aa83d5e84bfbe259cd511f6d7"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="structaicore__layertype.html">aicore_layertype_t</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="ailayer__batch__normalization_8h.html#af4710b2aa83d5e84bfbe259cd511f6d7">ailayer_batch_norm_type</a></td></tr>
<tr class="memdesc:af4710b2aa83d5e84bfbe259cd511f6d7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Batch Normalization layer type.  <a href="ailayer__batch__normalization_8h.html#af4710b2aa83d5e84bfbe259cd511f6d7">More...</a><br /></td></tr>
<tr class="separator:af4710b2aa83d5e84bfbe259cd511f6d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Base <a class="el" href="structailayer.html">layer </a> implementation of the Batch Normalization layer. </p>
<dl class="section version"><dt>Version</dt><dd>2.2.0 </dd></dl>
<dl class="section copyright"><dt>Copyright</dt><dd>Copyright (C) 2020-2023 Fraunhofer Institute for Microelectronic Circuits and Systems. All rights reserved.<br  />
<br  />
 AIfES is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.<br  />
<br  />
 This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.<br  />
<br  />
 You should have received a copy of the GNU Affero General Public License along with this program. If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</dd></dl>
<p>This is an "abstract" data-type independent implementation. To use the layer use one of the provided implementations for a specific hardware and data-type (for example from <a class="el" href="ailayer__batch__normalization__default_8h.html" title="Default implementation of the Batch Normalization layer .">ailayer_batch_normalization_default.h</a>) or set the required math functions on your own.</p>
<p>The <a href="https://arxiv.org/abs/1502.03167">Batch Normalization layer</a> can increase the training speed in deep neural networks by normalizing intermediate activations. For every element \( j \) neuron / channel \( i \) in the batch, the transformation is defined as </p><p class="formulaDsp">
\[ y_{i,j} = \mathit{BN}(x_{i,j}) = \gamma_i \cdot \frac{x_{i,j} - \mu_{i}}{\sqrt{\sigma_{i}^2+\epsilon}} + \beta_i \]
</p>
 <p class="formulaDsp">
\[ \mu_i = \frac{1}{m} \sum_{j=1}^{m} x_{i,j} \]
</p>
 <p class="formulaDsp">
\[ \sigma_i^2 = \frac{1}{m} \sum_{j=1}^{m} (x_{i,j} - \mu_i)^2 \]
</p>
<p> \( \beta_i \) and \( \gamma_i \) are trainable parameters of the layer.</p>
<p>Batch Normalization behaves different during training and during inference.</p>
<p>When in training mode (<code><a class="el" href="structailayer.html#ac0da37622121ce424bfefdeaaf924508" title="General layer settings like freezing weights or switching between training and evaluation mode.">ailayer.settings</a>[AILAYER_SETTINGS_TRAINING_MODE] = TRUE</code>), the means and variances ( \( \mu_i \) and \( \sigma_i^2 \)) are calculated for the whole batch during forward pass. Additionally, exponential moving averages of \( \mu_i \) and \( \sigma_i^2 \) are calculated to estimate these values for the inference mode.</p>
<p>In inference mode (<code><a class="el" href="structailayer.html#ac0da37622121ce424bfefdeaaf924508" title="General layer settings like freezing weights or switching between training and evaluation mode.">ailayer.settings</a>[AILAYER_SETTINGS_TRAINING_MODE] = FALSE</code>), \( \mu_i \) and \( \sigma_i^2 \) are taken as fixed parameters from the averages, which were collected during training.</p>
<p>Batch Normalization works best if a whole batch is processed at once in a forward pass, i.e. the first dimension of the input shape of the model equals the batch size. If this is the case, the layer will run in batch mode (<code><a class="el" href="structailayer.html#ac0da37622121ce424bfefdeaaf924508" title="General layer settings like freezing weights or switching between training and evaluation mode.">ailayer.settings</a>[AILAYER_SETTINGS_BATCH_MODE] = TRUE</code>) and calculates the means and variances for the batch as described above. Otherwise ( if the first input shape dimension is smaller than the batch size and therefore <code><a class="el" href="structailayer.html#ac0da37622121ce424bfefdeaaf924508" title="General layer settings like freezing weights or switching between training and evaluation mode.">ailayer.settings</a>[AILAYER_SETTINGS_BATCH_MODE] = FALSE</code>), the layer uses the exponential moving averages also for \( \mu_i \) and \( \sigma_i^2 \) during training. This reduces the memory required for intermediate activations, but it may decrease the training speed.</p>
<p>The results of the forward pass of this layer are written to the result tensor of the base ailayer_t struct. </p>
</div><h2 class="groupheader">Function Documentation</h2>
<a id="a43542b80dbaf9d65f72251d938dd0d84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43542b80dbaf9d65f72251d938dd0d84">&#9670;&nbsp;</a></span>ailayer_batch_norm()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structailayer.html">ailayer_t</a>* <a class="el" href="structailayer__batch__norm.html">ailayer_batch_norm</a> </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structailayer__batch__norm.html">ailayer_batch_norm_t</a> *&#160;</td>
          <td class="paramname"><em>layer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>input_layer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialize and connect the given Batch Normalization layer. </p>
<p>This function represents the "constructor" of the abstract Batch Normalization layer. It initializes the layer structure and connects it to the previous layer.<br  />
This function is not intended to call it directly. Instead use one of the data type specific implementations (like for example <a class="el" href="ailayer__batch__normalization__default_8h.html#a0c2e41aa208383db3214b3d501269d29" title="Initializes and connect a Batch Normalization layer  with the F32  default implementation.">ailayer_batch_norm_f32_default()</a>).</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*layer</td><td>The layer to initialize. </td></tr>
    <tr><td class="paramname">*input_layer</td><td>The previous layer that provides the inputs to the layer. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Pointer to the (successfully) initialized general layer structure (<a class="el" href="structailayer__batch__norm.html#ab13782a46e3804246bf82a92955096b3" title="Inherited field members from general ailayer struct.">ailayer_batch_norm.base</a>) </dd></dl>

</div>
</div>
<a id="a23613b98279575ed47e067fb92c195fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a23613b98279575ed47e067fb92c195fa">&#9670;&nbsp;</a></span>ailayer_batch_norm_backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ailayer_batch_norm_backward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate the backward pass for the given Batch Normalization layer. </p>
<p><em>Implementation of <a class="el" href="structailayer.html#a235e06f76bc9641b9c9b95ae29b56fe9" title="Calculate the backward pass and write the result to the deltas tensor.">ailayer.backward</a>.</em></p>
<p>It uses the deltas tensor of the next layer as input and writes the result of the backward pass to the deltas tensor (<a class="el" href="structailayer.html#a6e0cd193754d9614d5da823f0f0fcbf6" title="The result of the backward function is stored here.">ailayer.deltas</a>) of the given layer.</p>
<p>Calculates the gradients of \( \beta \) and \( \gamma \) and adds them to the corresponding gradients tensor.<br  />
 Calculates the gradients for backpropagation to the previous layer and writes them to \( \delta_{in} \).</p>
<p>Please refer to the paper by Ioffe and Szegedy (<a href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a>) for the equations of the gradients.</p>
<p>Used math functions:</p><ul>
<li><a class="el" href="structailayer__batch__norm.html#a3f31c6b5eadced42f76d88aac2fbe5b6" title="Required math function: Gradients of Batch Normalization.">ailayer_batch_norm.d_batch_norm</a></li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>Layer to calculate the backward path for. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aeae1413817112d97e2c6148780e23624"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeae1413817112d97e2c6148780e23624">&#9670;&nbsp;</a></span>ailayer_batch_norm_calc_result_shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ailayer_batch_norm_calc_result_shape </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate the shape of the result tensor (<a class="el" href="structailayer.html#a1ed86d1fec7aae68bc79c55f3f965790" title="The result of the forward function is stored here.">ailayer.result</a>) </p>
<p><em>Implementation of <a class="el" href="structailayer.html#a66787e37cfd371070476221e86386f7c" title="Calculate and write the shape to the result tensor.">ailayer.calc_result_shape</a>.</em></p>
<p>Resulting shape equals input shape.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>Layer to calculate the resulting shape for. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4143200f8e1c9a9ee8a4292c91c6adb4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4143200f8e1c9a9ee8a4292c91c6adb4">&#9670;&nbsp;</a></span>ailayer_batch_norm_forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ailayer_batch_norm_forward </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate the forward pass for given Batch Normalization layer. </p>
<p><em>Implementation of <a class="el" href="structailayer.html#a5fbd0ec6a416b01399233d98e60ca060" title="Calculate the forward pass and write the result to the result tensor.">ailayer.forward</a>.</em></p>
<p>It uses the result tensor of the previous layer as input and writes the result of the forward pass to the result tensor (<a class="el" href="structailayer.html#a1ed86d1fec7aae68bc79c55f3f965790" title="The result of the forward function is stored here.">ailayer.result</a>) of the given layer.</p>
<p>Calculation of the forward pass result:<br  />
 For every element \( j \) neuron / channel \( i \) in the batch, the transformation is defined as </p><p class="formulaDsp">
\[ x_{out;i,j} = \mathit{BN}(x_{in;i,j}) = \gamma_i \cdot \frac{x_{out;i,j} - \mu_{i}}{\sqrt{\sigma_{i}^2+\epsilon}} + \beta_i \]
</p>
 <p class="formulaDsp">
\[ \mu_i = \frac{1}{m} \sum_{j=1}^{m} x_{in;i,j} \]
</p>
 <p class="formulaDsp">
\[ \sigma_i^2 = \frac{1}{m} \sum_{j=1}^{m} (x_{in;i,j} - \mu_i)^2 \]
</p>
<p>\( \gamma \): Scaling vector<br  />
 \( \beta \): Offset vector<br  />
 \( \epsilon \): Small constant for numerical stability<br  />
 \( x_{in} \): Result of the forward pass of the previous layer<br  />
 \( x_{out} \): Result of the forward pass of this layer<br  />
<br  />
 Used math functions:</p><ul>
<li><a class="el" href="structailayer__batch__norm.html#a5db4592396e5ab43fc55de673c318aae" title="Required math function: Batch Normalization.">ailayer_batch_norm.batch_norm</a></li>
<li><a class="el" href="structailayer__batch__norm.html#a7a06fdbdd9e5f95ddc00f8bf65297f65" title="Required math function: Channel-wise empirical mean calculation.">ailayer_batch_norm.empirical_mean_channelwise</a></li>
<li><a class="el" href="structailayer__batch__norm.html#a05a2db6bf3cc2160f0b13c6cb3e31a18" title="Required math function: Channel-wise empirical variance calculation.">ailayer_batch_norm.empirical_variance_channelwise</a></li>
<li><a class="el" href="structailayer__batch__norm.html#ac42e8741878f9c5f21fa033e8dc344c4" title="Required math function: Exponential moving average.">ailayer_batch_norm.exponential_moving_average</a></li>
</ul>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>Layer to calculate the forward path for. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aa314fea512774e4b63bc25da3b030476"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa314fea512774e4b63bc25da3b030476">&#9670;&nbsp;</a></span>ailayer_batch_norm_print_specs()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ailayer_batch_norm_print_specs </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Print the layer specification. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>The layer to print the specification for </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ae3476d9d38ffe89b267e68b1c3fc748d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3476d9d38ffe89b267e68b1c3fc748d">&#9670;&nbsp;</a></span>ailayer_batch_norm_set_paramem()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ailayer_batch_norm_set_paramem </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>memory_ptr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Distribute provided memory to the parameter pointers. </p>
<p><em>Implementation of <a class="el" href="structailayer.html#a219921bd3b75e98894a33f6c2ff61c07" title="Set and distribute the memory block internally.">ailayer.set_paramem</a>.</em></p>
<p>Distributes the given buffer to the parameter pointers and sets the tensor parameters.<br  />
The required parameter size can be calculated with <a class="el" href="ailayer__batch__normalization_8h.html#aca69f294f48ca9f4c474d3a75d5bb5b4" title="Calculate and return the parameter memory size needed for this layer.">ailayer_batch_norm_sizeof_paramem()</a></p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>The layer to set the memory fields for. </td></tr>
    <tr><td class="paramname">*memory_ptr</td><td>The memory that can be used for the parameters </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a7047892ab2ce5b21a2581f47d8b43c60"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7047892ab2ce5b21a2581f47d8b43c60">&#9670;&nbsp;</a></span>ailayer_batch_norm_set_trainmem()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ailayer_batch_norm_set_trainmem </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>memory_ptr</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Distribute provided memory to the gradients pointers. </p>
<p><em>Implementation of <a class="el" href="structailayer.html#a5062b6bf991a3ae278941c560847eeb6" title="Set and distribute the memory block internally.">ailayer.set_trainmem</a>.</em></p>
<p>The required memory size can be calculated with <a class="el" href="ailayer__batch__normalization_8h.html#a39b286297ae7e1163676e98b4c9d21ea" title="Calculate and return the memory size needed by this layer for training.">ailayer_batch_norm_sizeof_trainmem()</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>The layer to set the memory fields for. </td></tr>
    <tr><td class="paramname">*memory_ptr</td><td>The memory that can be used for the gradients </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="aca69f294f48ca9f4c474d3a75d5bb5b4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca69f294f48ca9f4c474d3a75d5bb5b4">&#9670;&nbsp;</a></span>ailayer_batch_norm_sizeof_paramem()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t ailayer_batch_norm_sizeof_paramem </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate and return the parameter memory size needed for this layer. </p>
<p><em>Implementation of <a class="el" href="structailayer.html#ab758b2be3966c7cc0bf6920a60886bbf" title="Size of required memory (in bytes).">ailayer.sizeof_paramem</a>.</em></p>
<p>The parameter size is calculated for the <a class="el" href="structailayer__batch__norm.html#a81edfab4c4a52c6537f3f0ee19a0d2a4">gammas </a>, <a class="el" href="structailayer__batch__norm.html#a88bc32827b45ca03a858d6dbc85b9a48">betas </a>, <a class="el" href="structailayer__batch__norm.html#ae61aaf16d54970d405095a058b233656">moving means </a> and <a class="el" href="structailayer__batch__norm.html#ab30bca8df727bfc450468830d31adf1c">moving variances </a> tensors.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>The layer to calculate the parameter memory size for </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Calculated parameter memory size in bytes. </dd></dl>

</div>
</div>
<a id="a39b286297ae7e1163676e98b4c9d21ea"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a39b286297ae7e1163676e98b4c9d21ea">&#9670;&nbsp;</a></span>ailayer_batch_norm_sizeof_trainmem()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t ailayer_batch_norm_sizeof_trainmem </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structailayer.html">ailayer_t</a> *&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate and return the memory size needed by this layer for training. </p>
<p><em>Implementation of <a class="el" href="structailayer.html#af95ecd0e925bff73b30b1d1b6fc21028" title="Size of required memory (in bytes).">ailayer.sizeof_trainmem</a>.</em></p>
<p>The memory size is calculated for the <a class="el" href="structailayer__batch__norm.html#ab11481f30ddb112f3febd5f656e6f238">means </a> and <a class="el" href="structailayer__batch__norm.html#a4cb00bf5961c120ec73810203638243e">variances </a> and for the gradient tensors of <a class="el" href="structailayer__batch__norm.html#a81edfab4c4a52c6537f3f0ee19a0d2a4">gammas </a> and <a class="el" href="structailayer__batch__norm.html#a88bc32827b45ca03a858d6dbc85b9a48">betas </a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">*self</td><td>The layer to calculate the gradient memory size for. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Calculated gradient memory size in bytes. </dd></dl>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="af4710b2aa83d5e84bfbe259cd511f6d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4710b2aa83d5e84bfbe259cd511f6d7">&#9670;&nbsp;</a></span>ailayer_batch_norm_type</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="structaicore__layertype.html">aicore_layertype_t</a>* ailayer_batch_norm_type</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">extern</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Batch Normalization layer type. </p>
<p>Defines the type of the layer (for example for type checks and debug prints). See <a class="el" href="structaicore__layertype.html" title="Type indicator of the layer.">aicore_layertype</a> for more information about the layer type. </p>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_5233a5861230ad4bc52bfd822c86fe04.html">cnn</a></li><li class="navelem"><a class="el" href="dir_a5c91e9bbf64c4b6a24d0c0102e9d7da.html">base</a></li><li class="navelem"><a class="el" href="dir_115795935351339455fee6eae515097b.html">ailayer</a></li><li class="navelem"><a class="el" href="ailayer__batch__normalization_8h.html">ailayer_batch_normalization.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
